<img src='https://www.di.uniroma1.it/sites/all/themes/sapienza_bootstrap/logo.png' width="200"/> 

# [Natural Language Processing](https://iacopomasi.github.io/NLP/)
Course Material for Natural Language Processing @ Computer Science Dept, Sapienza
Master in [Computer Science](https://www.studiareinformatica.uniroma1.it/master-course-computer-science)

### **Tutor**:
- [Prof. Masi](https://corsidilaurea.uniroma1.it/it/users/iacopomasiuniroma1it)
- [Prof. Faralli](https://corsidilaurea.uniroma1.it/it/users/stefanofaralliuniroma1it)
    
### **Teacher Assistance:**
- Parham Membari   
    - <img src="https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png" alt="Logo" width="20" height="20"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/p-mem/)  
    - <img src="https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg" alt="Logo" width="20" height="20"> **GitHub**: [GitHub](https://github.com/parham075)  
    
- Robert Adrian Minut
    - <img src="https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png" alt="Logo" width="20" height="20"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/adrian-robert-minut/)  
    - <img src="https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg" alt="Logo" width="20" height="20"> **GitHub**: [GitHub](https://github.com/adrianrob1)  
    
## Syllabus at a glance

### NLP fundamentals and downstream tasks - Part I
#### [Prof. Faralli](https://corsidilaurea.uniroma1.it/it/users/stefanofaralliuniroma1it)
- Introduction to NLP, Regular Expressions, Finite State Automata and REs
- Words, Corpora and Text Normalization
- Spelling Correction and Minimum Edit Distance
- Language models, Part-of-speech-tagging
- Hidden Markov Model, Viterbi Algorithm, Logistic Regression
- Syntax, Semantics, Vector semantics (sparse), NLP tasks

### Neural and multimodal NLP - Part II
#### [Prof. Masi](https://corsidilaurea.uniroma1.it/it/users/iacopomasiuniroma1it)
- Latent Semantic Analysis and word2vec [hierarchical softmax & neg. sampling]
- Scaling word2vec, Sentiment Analysis, Language Model w/ Neural Nets
- Sequence modeling w/ Deep Learning: LM /w RNN, POS, Image Captioning
- from LSTM to Transformers
- Neural Machine Translation, Encoder/Decoder, Beam Search
- Contextual Embedding: BERT, GPT, Transfer Learning
- Multimodal NLP: Diffusion models (images), NLP as supervision for Vision (CLIP)
- text2image application (Dall-E 2): based on diffusion and CLIP


## Material

## ðŸ“– Course Material 

It is in the form of Jupyter Notebook slides with LaTeX math, code, drawings, plots and explanations

- Slides and material will be uploaded before every lecture on Google Classroom and here.
- Good starting point but **but may be not enough**.
- [Textbooks](textbooks) are required.


## Material 


**Date**       | **Topic**          | **NBviewer**        |  **Github**   |    **Colab**
:------------: | :------------:     | :------------:    |:------------: |:------------:
|              |                    |                   |  				|			|
| __Word embeddings__    |                    |                   |   		|			|
April 16, 18     | LSA, intro word2vec | [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_01_lsa_intro_word2vec/2_01_lsa_intro_word2vec.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_01_lsa_intro_word2vec/)       | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vY7xO00MoM7EV6muMqL02-8VnmKXPkLd?usp=sharing) 
|              |                    |                   |               | 	 |			|  		|
April 23, 30     | scaling word2vec, Sentiment Analysis, Language Model w/ NN| [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_02_word2vec_neural_nets/2_02_word2vec_neural_nets.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_02_word2vec_neural_nets/)       |  
|              |                    |                   |               | 	 |			|  		|
April 30, May 2, 7    | Deep learning for Seq. Processing | [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_03_seq_processing/2_03_seq_processing.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_03_seq_processing/)       |  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hSWSvOte-JozTPDvEI1t2HWap1OA11ZS?usp=sharing) 
|              |                    |                   |               | 	 |			|        |
May 9, 14     | From RNN to Neural Machine Translation | [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_04_from_rnn_to_nmt/2_04_from_rnn_to_nmt.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_04_from_rnn_to_nmt/)       |  
|              |                    |                   |               | 	 |			| 
May 14, 21    | Transformers, BERT, Pre-training | [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_05_transformers_bert/2_05_transformers_bert.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_05_transformers_bert/)       |  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13owxHTGEWuGZria32xylXb5SF_GSU-4Y?usp=sharing) 
|              |                    |                   |               | 	 |			|        |
May 28    | ExamPrep, CLIP | [![nbviewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/iacopomasi/NLP/blob/main/course/AA2324/2_06_clip_diffusion/2_06_clip_diffusion.ipynb)       |  [![Download](https://badgen.net/badge/icon/download?icon=terminal&label)](https://github.com/iacopomasi/NLP/blob/main/course/AA2324/2_06_clip_diffusion/)       |  
|              |                    |                   |               | 	 |			|        |


### How to open the presentations locally

The following commands have been tested on a Linux machine.
In case you are running another OS, please adapt them to your specific situation.

1. Clone the repository
```sh
git clone https://github.com/iacopomasi/NLP.git
cd NLP/
```
2. Install the dependencies in a virtualenv
```sh
pytho3.10n -m venv .venv  # Python 3.10
source .venv/bin/activate
pip install -r requirements.txt
```
3. Run Jupyter
```sh
jupyter notebook
```
4. In the browser that automatically opens up:
    - Open the folder where the .ipynb is
    - Open the .ipynb presentation you want to see
    - Click on this button to start the presentation

![RISE start presentation button](.github/assets/rise_button.png)

